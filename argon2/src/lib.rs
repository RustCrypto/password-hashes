//! Argon2 password hashing function.

#![no_std]
#![doc(
    html_logo_url = "https://raw.githubusercontent.com/RustCrypto/meta/master/logo.svg",
    html_favicon_url = "https://raw.githubusercontent.com/RustCrypto/meta/master/logo.svg"
)]
#![forbid(unsafe_code)]
#![warn(rust_2018_idioms)] // add: missing_docs

// TODO(disallow)
#![allow(non_camel_case_types, non_snake_case)]
#![allow(clippy::too_many_arguments, clippy::absurd_extreme_comparisons)]

#[macro_use]
extern crate alloc;

use alloc::vec::Vec;
use blake2::{
    digest::{self, VariableOutput},
    Blake2b, Digest, VarBlake2b,
};
use core::{convert::TryInto, num::Wrapping};

#[cfg(feature = "zeroize")]
use zeroize::Zeroize;

/// Minimum and maximum number of lanes (degree of parallelism)
pub const ARGON2_MIN_LANES: u32 = 1;

/// Minimum and maximum number of lanes (degree of parallelism)
pub const ARGON2_MAX_LANES: u32 = 0xFFFFFF;

/// Minimum and maximum number of threads
pub const ARGON2_MIN_THREADS: u32 = 1;

/// Minimum and maximum number of threads
pub const ARGON2_MAX_THREADS: u32 = 0xFFFFFF;

/// Minimum digest size in bytes
pub const ARGON2_MIN_OUTLEN: usize = 4;

/// Maximum digest size in bytes
pub const ARGON2_MAX_OUTLEN: usize = 0xFFFFFFFF;

/// Minimum number of memory blocks (each of [`BLOCK_SIZE`] bytes)
pub const ARGON2_MIN_MEMORY: u32 = 2 * ARGON2_SYNC_POINTS; // 2 blocks per slice

/// Maximum number of memory blocks (each of [`BLOCK_SIZE`] bytes)
// TODO(tarcieri): Max memory size is addressing-space/2, topping at 2^32 blocks (4 TB)
pub const ARGON2_MAX_MEMORY: u32 = 0x0FFFFFFF;

/// Minimum number of passes
pub const ARGON2_MIN_TIME: u32 = 1;

/// Maximum number of passes
pub const ARGON2_MAX_TIME: u32 = 0xFFFFFFFF;

/// Maximum password length in bytes
pub const ARGON2_MAX_PWD_LENGTH: usize = 0xFFFFFFFF;

/// Minimum and maximum associated data length in bytes
pub const ARGON2_MAX_AD_LENGTH: usize = 0xFFFFFFFF;

/// Minimum and maximum salt length in bytes
pub const ARGON2_MIN_SALT_LENGTH: usize = 8;

/// Maximum salt length in bytes
pub const ARGON2_MAX_SALT_LENGTH: usize = 0xFFFFFFFF;

/// Maximum key length in bytes
pub const ARGON2_MAX_SECRET: usize = 0xFFFFFFFF;

/// Number of synchronization points between lanes per pass
const ARGON2_SYNC_POINTS: u32 = 4;

/// Memory block size in bytes
const ARGON2_BLOCK_SIZE: usize = 1024;

/// Quadwords in block
const ARGON2_QWORDS_IN_BLOCK: usize = ARGON2_BLOCK_SIZE / 8;

/// Number of pseudo-random values generated by one call to Blake in Argon2i
/// to generate reference block positions
const ARGON2_ADDRESSES_IN_BLOCK: u32 = 128;

/// Output size of BLAKE2b in bytes
const BLAKE2B_OUTBYTES: usize = 64;

/// Error type
#[derive(Copy, Clone, Debug, Eq, PartialEq)]
pub enum Error {
    ARGON2_AD_TOO_LONG,
    ARGON2_LANES_TOO_FEW,
    ARGON2_LANES_TOO_MANY,
    ARGON2_MEMORY_TOO_LITTLE,
    ARGON2_MEMORY_TOO_MUCH,
    ARGON2_OUTPUT_TOO_LONG,
    ARGON2_OUTPUT_TOO_SHORT,
    ARGON2_PWD_TOO_LONG,
    ARGON2_SALT_TOO_SHORT,
    ARGON2_SALT_TOO_LONG,
    ARGON2_SECRET_TOO_LONG,
    ARGON2_THREADS_TOO_FEW,
    ARGON2_THREADS_TOO_MANY,
    ARGON2_TIME_TOO_SMALL,
    ARGON2_TIME_TOO_LARGE,
}

pub type Result<T> = core::result::Result<T, Error>;

/// Argon2 primitive type
#[derive(Copy, Clone, Debug, Eq, PartialEq, PartialOrd, Ord)]
pub enum Argon2_type {
    Argon2_d = 0,
    Argon2_i = 1,
    Argon2_id = 2,
}

impl Argon2_type {
    /// Serialize primitive type as little endian bytes
    fn to_le_bytes(self) -> [u8; 4] {
        (self as u32).to_le_bytes()
    }
}

/// Version of the algorithm
#[derive(Copy, Clone, Debug, Eq, PartialEq, PartialOrd, Ord)]
#[repr(u32)]
pub enum Argon2_version {
    ARGON2_VERSION_10 = 0x10,
    ARGON2_VERSION_13 = 0x13,
}

impl Argon2_version {
    /// Serialize version as little endian bytes
    fn to_le_bytes(self) -> [u8; 4] {
        (self as u32).to_le_bytes()
    }
}

impl Default for Argon2_version {
    fn default() -> Self {
        Self::ARGON2_VERSION_13
    }
}

/// Hash the given password with Argon2
pub fn argon2_hash(
    t_cost: u32,
    m_cost: u32,
    parallelism: u32,
    pwd: &impl AsRef<[u8]>,
    salt: &[u8],
    out: &mut [u8],
    argon2_type: Argon2_type,
    version: Argon2_version,
) -> Result<()> {
    if pwd.as_ref().len() > ARGON2_MAX_PWD_LENGTH {
        return Err(Error::ARGON2_PWD_TOO_LONG);
    }

    if salt.len() > ARGON2_MAX_SALT_LENGTH {
        return Err(Error::ARGON2_SALT_TOO_LONG);
    }

    if out.len() > ARGON2_MAX_OUTLEN {
        return Err(Error::ARGON2_OUTPUT_TOO_LONG);
    }

    if out.len() < ARGON2_MIN_OUTLEN {
        return Err(Error::ARGON2_OUTPUT_TOO_SHORT);
    }

    let ctx = Argon2_Context::new(None, t_cost, m_cost, parallelism, version)?;

    ctx.perform(argon2_type, pwd.as_ref(), salt, b"", out)
}

/// Context: structure to hold Argon2 inputs:
///
/// - output array and its length,
/// - password and its length,
/// - salt and its length,
/// - secret and its length,
/// - associated data and its length,
/// - number of passes, amount of used memory (in KBytes, can be rounded up a bit)
/// - number of parallel threads that will be run.
///
/// All the parameters above affect the output hash value.
/// Additionally, two function pointers can be provided to allocate and
/// deallocate the memory (if NULL, memory will be allocated internally).
/// Also, three flags indicate whether to erase password, secret as soon as they
/// are pre-hashed (and thus not needed anymore), and the entire memory
///
/// Simplest situation: you have output array `out[8]`, password is stored in
/// `pwd[32]`, salt is stored in `salt[16]`, you do not have keys nor associated
/// data.
///
/// You need to spend 1 GB of RAM and you run 5 passes of Argon2d with
/// 4 parallel lanes.
///
/// You want to erase the password, but you're OK with last pass not being
/// erased.
pub struct Argon2_Context<'key> {
    /// Key array
    secret: Option<&'key [u8]>,

    /// Number of passes
    t_cost: u32,

    /// Amount of memory requested (kB)
    m_cost: u32,

    /// Number of lanes
    lanes: u32,

    /// Maximum number of threads
    threads: u32,

    /// Version number
    version: Argon2_version,
}

impl<'key> Argon2_Context<'key> {
    /// Create a new Argon2 context
    pub fn new(
        secret: Option<&'key [u8]>,
        t_cost: u32,
        m_cost: u32,
        parallelism: u32,
        version: Argon2_version,
    ) -> Result<Self> {
        Ok(Self {
            secret,
            t_cost,
            m_cost,
            lanes: parallelism,
            threads: parallelism,
            version,
        })
    }

    /// Function that performs memory-hard hashing with certain degree of parallelism.
    /// NOTE(tarcieri): originally `argon2_ctx()`
    pub fn perform(
        &self,
        argon2_type: Argon2_type,
        pwd: &[u8],
        salt: &[u8],
        ad: &[u8],
        out: &mut [u8],
    ) -> Result<()> {
        // Validate all inputs
        self.validate_inputs(pwd, salt, ad, out)?;

        // Hashing all inputs
        #[allow(unused_mut)]
        let mut initial_hash = self.initial_hash(argon2_type, pwd, salt, ad, out);

        // Initialization: hashing inputs, allocating memory, filling first blocks
        let mut instance = Argon2_instance::initialize(self, argon2_type, &initial_hash)?;

        #[cfg(feature = "zeroize")]
        initial_hash.zeroize();

        // Filling memory
        instance.fill_memory_blocks();

        // Finalization
        instance.finalize(out)
    }

    /// Function that validates all inputs against predefined restrictions
    fn validate_inputs(&self, pwd: &[u8], salt: &[u8], ad: &[u8], out: &[u8]) -> Result<()> {
        if let Some(secret) = &self.secret {
            if ARGON2_MAX_SECRET < secret.len() {
                return Err(Error::ARGON2_SECRET_TOO_LONG);
            }
        }

        // Validate output length
        if ARGON2_MIN_OUTLEN > out.len() {
            return Err(Error::ARGON2_OUTPUT_TOO_SHORT);
        }

        if ARGON2_MAX_OUTLEN < out.len() {
            return Err(Error::ARGON2_OUTPUT_TOO_LONG);
        }

        if ARGON2_MAX_PWD_LENGTH < pwd.len() {
            return Err(Error::ARGON2_PWD_TOO_LONG);
        }

        // Validate salt (required param)
        if ARGON2_MIN_SALT_LENGTH > salt.len() {
            return Err(Error::ARGON2_SALT_TOO_SHORT);
        }

        if ARGON2_MAX_SALT_LENGTH < salt.len() {
            return Err(Error::ARGON2_SALT_TOO_LONG);
        }

        // Validate associated data (optional param)
        if ARGON2_MAX_AD_LENGTH < ad.len() {
            return Err(Error::ARGON2_AD_TOO_LONG);
        }

        // Validate memory cost
        if ARGON2_MIN_MEMORY > self.m_cost {
            return Err(Error::ARGON2_MEMORY_TOO_LITTLE);
        }

        if ARGON2_MAX_MEMORY < self.m_cost {
            return Err(Error::ARGON2_MEMORY_TOO_MUCH);
        }

        if self.m_cost < 8 * self.lanes {
            return Err(Error::ARGON2_MEMORY_TOO_LITTLE);
        }

        // Validate time cost
        if ARGON2_MIN_TIME > self.t_cost {
            return Err(Error::ARGON2_TIME_TOO_SMALL);
        }

        if ARGON2_MAX_TIME < self.t_cost {
            return Err(Error::ARGON2_TIME_TOO_LARGE);
        }

        // Validate lanes
        if ARGON2_MIN_LANES > self.lanes {
            return Err(Error::ARGON2_LANES_TOO_FEW);
        }

        if ARGON2_MAX_LANES < self.lanes {
            return Err(Error::ARGON2_LANES_TOO_MANY);
        }

        // Validate threads
        if ARGON2_MIN_THREADS > self.threads {
            return Err(Error::ARGON2_THREADS_TOO_FEW);
        }

        if ARGON2_MAX_THREADS < self.threads {
            return Err(Error::ARGON2_THREADS_TOO_MANY);
        }

        Ok(())
    }

    /// Hashes all the inputs into `blockhash[PREHASH_DIGEST_LENGTH]`.
    fn initial_hash(
        &self,
        argon2_type: Argon2_type,
        pwd: &[u8],
        salt: &[u8],
        ad: &[u8],
        out: &[u8],
    ) -> digest::Output<Blake2b> {
        let mut digest = Blake2b::new();
        digest.update(&self.lanes.to_le_bytes());
        digest.update(&(out.len() as u32).to_le_bytes());
        digest.update(&self.m_cost.to_le_bytes());
        digest.update(&self.t_cost.to_le_bytes());
        digest.update(&self.version.to_le_bytes());
        digest.update(&argon2_type.to_le_bytes());
        digest.update(&(pwd.len() as u32).to_le_bytes());
        digest.update(pwd);
        digest.update(&(salt.len() as u32).to_le_bytes());
        digest.update(salt);

        if let Some(secret) = &self.secret {
            digest.update(&(secret.len() as u32).to_le_bytes());
            digest.update(secret);
        } else {
            digest.update(0u32.to_le_bytes());
        }

        digest.update(&(ad.len() as u32).to_le_bytes());
        digest.update(ad);

        digest.finalize()
    }
}

/// Argon2 instance: memory pointer, number of passes, amount of memory, type,
/// and derived values.
///
/// Used to evaluate the number and location of blocks to construct in each
/// thread.
pub struct Argon2_instance {
    /// Memory blocks
    memory: Vec<Block>,

    /// Version
    version: Argon2_version,

    /// Number of passes
    passes: u32,

    /// Number of blocks in memory
    memory_blocks: usize,

    /// Segment length
    segment_length: u32,

    /// Lane length
    lane_length: u32,

    /// Number of lanes
    lanes: u32,

    /// Number of threads
    threads: u32,

    /// Argon2 type
    argon2_type: Argon2_type,
}

impl Argon2_instance {
    /// Function allocates memory, hashes the inputs with Blake, and creates first
    /// two blocks.
    ///
    /// Returns struct containing main memory with 2 blocks per lane initialized.
    fn initialize(
        context: &Argon2_Context<'_>,
        argon2_type: Argon2_type,
        initial_hash: &digest::Output<Blake2b>,
    ) -> Result<Self> {
        // Align memory size
        // Minimum memory_blocks = 8L blocks, where L is the number of lanes
        let mut memory_blocks = context.m_cost;

        if memory_blocks < 2 * ARGON2_SYNC_POINTS * context.lanes {
            memory_blocks = 2 * ARGON2_SYNC_POINTS * context.lanes;
        }

        let segment_length = memory_blocks / (context.lanes * ARGON2_SYNC_POINTS);

        // Ensure that all segments have equal length
        let memory_blocks = (segment_length * context.lanes * ARGON2_SYNC_POINTS) as usize;
        let memory = vec![Block::default(); memory_blocks];

        let mut instance = Argon2_instance {
            version: context.version,
            memory,
            passes: context.t_cost,
            memory_blocks,
            segment_length,
            lane_length: segment_length * ARGON2_SYNC_POINTS,
            lanes: context.lanes,
            threads: context.threads,
            argon2_type,
        };

        if instance.threads > instance.lanes {
            instance.threads = instance.lanes;
        }

        // TODO(tarcieri): GENKAT
        // initial_kat(initial_hash, context, instance->type);

        // Creating first blocks, we always have at least two blocks in a slice
        instance.fill_first_blocks(&initial_hash)?;

        Ok(instance)
    }

    /// Function creates first 2 blocks per lane
    fn fill_first_blocks(&mut self, blockhash: &[u8]) -> Result<()> {
        let mut hash = [0u8; ARGON2_BLOCK_SIZE];

        for l in 0..self.lanes {
            // Make the first and second block in each lane as G(H0||0||i) or
            // G(H0||1||i)
            for i in 0u32..2u32 {
                blake2b_long(&[blockhash, &i.to_le_bytes(), &l.to_le_bytes()], &mut hash)?;
                self.memory[(l * self.lane_length + i) as usize].load_block(&hash);
            }
        }

        Ok(())
    }

    /// Function that fills the entire memory t_cost times based on the first two
    /// blocks in each lane
    fn fill_memory_blocks(&mut self) {
        // TODO(tarcieri): multithread support
        // Single-threaded version for p=1 case
        for r in 0..self.passes {
            for s in 0..ARGON2_SYNC_POINTS {
                for l in 0..self.lanes {
                    self.fill_segment(Argon2_position {
                        pass: r,
                        lane: l,
                        slice: s,
                        index: 0,
                    });
                }
            }

            // TODO(tarcieri): GENKAT
            // internal_kat(self, r); // Print all memory blocks
            // for (i, block) in self.memory.iter().enumerate() {
            //     for (j, n) in block.0.iter().enumerate() {
            //         println!("Block {} [{}] {:x}", i, j, n);
            //     }
            // }
        }
    }

    /// Function that fills the segment using previous segments
    // TODO(tarcieri): optimized implementation (i.e. from opt.c instead of ref.c)
    fn fill_segment(&mut self, mut position: Argon2_position) {
        let mut address_block = Block::default();
        let mut input_block = Block::default();
        let zero_block = Block::default();

        let data_independent_addressing = (self.argon2_type == Argon2_type::Argon2_i)
            || (self.argon2_type == Argon2_type::Argon2_id
                && (position.pass == 0)
                && (position.slice < ARGON2_SYNC_POINTS / 2));

        if data_independent_addressing {
            input_block.0[0] = position.pass as u64;
            input_block.0[1] = position.lane as u64;
            input_block.0[2] = position.slice as u64;
            input_block.0[3] = self.memory_blocks as u64;
            input_block.0[4] = self.passes as u64;
            input_block.0[5] = self.argon2_type as u64;
        }

        let mut starting_index = 0;

        if position.pass == 0 && position.slice == 0 {
            starting_index = 2; // we have already generated the first two blocks

            // Don't forget to generate the first block of addresses
            if data_independent_addressing {
                next_addresses(&mut address_block, &mut input_block, &zero_block);
            }
        }

        // Offset of the current block
        let mut curr_offset = position.lane * self.lane_length
            + position.slice * self.segment_length
            + starting_index;

        let mut prev_offset = if 0 == curr_offset % self.lane_length {
            // Last block in this lane
            curr_offset + self.lane_length - 1
        } else {
            // Previous block
            curr_offset - 1
        };

        for i in starting_index..self.segment_length {
            // 1.1 Rotating prev_offset if needed
            if curr_offset % self.lane_length == 1 {
                prev_offset = curr_offset - 1;
            }

            // 1.2 Computing the index of the reference block
            // 1.2.1 Taking pseudo-random value from the previous block
            let pseudo_rand = if data_independent_addressing {
                if i % ARGON2_ADDRESSES_IN_BLOCK == 0 {
                    next_addresses(&mut address_block, &mut input_block, &zero_block);
                }
                address_block.0[(i % ARGON2_ADDRESSES_IN_BLOCK) as usize]
            } else {
                self.memory[prev_offset as usize].0[0]
            };

            // 1.2.2 Computing the lane of the reference block
            let mut ref_lane = (pseudo_rand >> 32) as u32 % self.lanes;

            if position.pass == 0 && position.slice == 0 {
                // Can not reference other lanes yet
                ref_lane = position.lane;
            }

            // 1.2.3 Computing the number of possible reference block within the lane.
            position.index = i;

            let ref_index = self.index_alpha(
                position,
                (pseudo_rand & 0xFFFFFFFF) as u32,
                ref_lane == position.lane,
            );

            // 2 Creating a new block
            let ref_block = self.memory[(self.lane_length * ref_lane + ref_index) as usize];
            let prev_block = self.memory[prev_offset as usize];

            // version 1.2.1 and earlier: overwrite, not XOR
            let without_xor =
                self.version == Argon2_version::ARGON2_VERSION_10 || position.pass == 0;

            self.memory[curr_offset as usize].fill_block(prev_block, ref_block, !without_xor);

            curr_offset += 1;
            prev_offset += 1;
        }
    }

    /// Computes absolute position of reference block in the lane following a skewed
    /// distribution and using a pseudo-random value as input.
    ///
    /// # Params
    /// - `position`: Pointer to the current position
    /// - `pseudo_rand`: 32-bit pseudo-random value used to determine the position
    /// - `same_lane`: Indicates if the block will be taken from the current lane.
    ///                If so we can reference the current segment.
    fn index_alpha(&self, position: Argon2_position, pseudo_rand: u32, same_lane: bool) -> u32 {
        // Pass 0:
        // - This lane: all already finished segments plus already constructed
        //   blocks in this segment
        // - Other lanes: all already finished segments
        //
        // Pass 1+:
        // - This lane: (SYNC_POINTS - 1) last segments plus already constructed
        //   blocks in this segment
        // - Other lanes : (SYNC_POINTS - 1) last segments
        let reference_area_size = if 0 == position.pass {
            // First pass
            if position.slice == 0 {
                // First slice
                position.index - 1 // all but the previous
            } else if same_lane {
                // The same lane => add current segment
                position.slice * self.segment_length + position.index - 1
            } else {
                position.slice * self.segment_length - if position.index == 0 { 1 } else { 0 }
            }
        } else {
            // Second pass
            if same_lane {
                self.lane_length - self.segment_length + position.index - 1
            } else {
                self.lane_length - self.segment_length - if position.index == 0 { 1 } else { 0 }
            }
        };

        // 1.2.4. Mapping pseudo_rand to 0..<reference_area_size-1> and produce
        // relative position
        let mut relative_position = pseudo_rand as u64;
        relative_position = (relative_position * relative_position) >> 32;
        let relative_position = reference_area_size
            - 1
            - (((reference_area_size as u64 * relative_position) >> 32) as u32);

        // 1.2.5 Computing starting position
        let mut start_position = 0;

        if position.pass != 0 {
            start_position = if position.slice == ARGON2_SYNC_POINTS - 1 {
                0
            } else {
                (position.slice + 1) * self.segment_length
            }
        }

        // 1.2.6. Computing absolute position
        (start_position + relative_position as u32) % self.lane_length
    }

    /// XORing the last block of each lane, hashing it, making the tag.
    fn finalize(&mut self, out: &mut [u8]) -> Result<()> {
        let mut blockhash = self.memory[(self.lane_length - 1) as usize];

        // XOR the last blocks
        for l in 1..self.lanes {
            let last_block_in_lane = l * self.lane_length + (self.lane_length - 1);
            blockhash.xor_block(&self.memory[last_block_in_lane as usize]);
        }

        // Hash the result
        let mut blockhash_bytes = [0u8; ARGON2_BLOCK_SIZE];

        for (chunk, v) in blockhash_bytes.chunks_mut(8).zip(blockhash.0.iter()) {
            chunk.copy_from_slice(&v.to_le_bytes())
        }

        blake2b_long(&[&blockhash_bytes], out)?;

        #[cfg(feature = "zeroize")]
        blockhash.zeroize();

        #[cfg(feature = "zeroize")]
        blockhash_bytes.zeroize();

        Ok(())
    }
}

fn next_addresses(address_block: &mut Block, input_block: &mut Block, zero_block: &Block) {
    input_block.0[6] += 1;
    address_block.fill_block(*zero_block, *input_block, false);
    address_block.fill_block(*zero_block, *address_block, false);
}

/// Structure for the (1KB) memory block implemented as 128 64-bit words.
// TODO(tarcieri): remove `pub`
#[derive(Copy, Clone, Debug)]
pub struct Block([u64; ARGON2_QWORDS_IN_BLOCK]);

impl Default for Block {
    fn default() -> Self {
        Self([0u64; ARGON2_QWORDS_IN_BLOCK])
    }
}

impl Block {
    fn load_block(&mut self, input: &[u8]) {
        debug_assert_eq!(input.len(), ARGON2_BLOCK_SIZE);

        for (i, chunk) in input.chunks(8).enumerate() {
            self.0[i] = u64::from_le_bytes(chunk.try_into().unwrap());
        }
    }

    // TODO(tarcieri): get rid of this with `Copy`
    fn copy_block(&mut self, other: &Block) {
        for (a, b) in self.0.iter_mut().zip(other.0.iter()) {
            *a = *b;
        }
    }

    fn xor_block(&mut self, other: &Block) {
        for (a, b) in self.0.iter_mut().zip(other.0.iter()) {
            *a ^= *b;
        }
    }

    /// Function fills a new memory block and optionally XORs the old block over the new one.
    // TODO(tarcieri): optimized implementation (i.e. from opt.c instead of ref.c)
    fn fill_block(&mut self, prev_block: Block, ref_block: Block, with_xor: bool) {
        let mut blockR = Block::default();
        let mut block_tmp = Block::default();

        // TODO(tarcieri): get rid of this with `Copy`
        blockR.copy_block(&ref_block);
        blockR.xor_block(&prev_block);
        block_tmp.copy_block(&blockR);

        // Now blockR = ref_block + prev_block and block_tmp = ref_block + prev_block
        if with_xor {
            // Saving the next block contents for XOR over
            block_tmp.xor_block(self);
            // Now blockR = ref_block + prev_block and
            // block_tmp = ref_block + prev_block + next_block
        }

        /// Blake2 round function
        // TODO(tarcieri): use the `blake2` crate
        macro_rules! blake2_round {
            (
                $v0:expr, $v1:expr, $v2:expr, $v3:expr, $v4:expr, $v5:expr, $v6:expr, $v7:expr,
                $v8:expr, $v9:expr, $v10:expr, $v11:expr, $v12:expr, $v13:expr, $v14:expr, $v15:expr
            ) => {
                blake2_inner!($v0, $v4, $v8, $v12);
                blake2_inner!($v1, $v5, $v9, $v13);
                blake2_inner!($v2, $v6, $v10, $v14);
                blake2_inner!($v3, $v7, $v11, $v15);
                blake2_inner!($v0, $v5, $v10, $v15);
                blake2_inner!($v1, $v6, $v11, $v12);
                blake2_inner!($v2, $v7, $v8, $v13);
                blake2_inner!($v3, $v4, $v9, $v14);
            };
        }

        macro_rules! blake2_inner {
            ($a:expr, $b:expr, $c:expr, $d:expr) => {
                $a = fBlaMka($a, $b);
                $d = rotr64($d ^ $a, 32);
                $c = fBlaMka($c, $d);
                $b = rotr64($b ^ $c, 24);
                $a = fBlaMka($a, $b);
                $d = rotr64($d ^ $a, 16);
                $c = fBlaMka($c, $d);
                $b = rotr64($b ^ $c, 63);
            };
        }

        // Apply Blake2 on columns of 64-bit words: (0, 1, ..., 15), then
        // (16, 17, ..31)... finally (112, 113, ...127)
        for i in 0..8 {
            blake2_round!(
                blockR.0[16 * i],
                blockR.0[16 * i + 1],
                blockR.0[16 * i + 2],
                blockR.0[16 * i + 3],
                blockR.0[16 * i + 4],
                blockR.0[16 * i + 5],
                blockR.0[16 * i + 6],
                blockR.0[16 * i + 7],
                blockR.0[16 * i + 8],
                blockR.0[16 * i + 9],
                blockR.0[16 * i + 10],
                blockR.0[16 * i + 11],
                blockR.0[16 * i + 12],
                blockR.0[16 * i + 13],
                blockR.0[16 * i + 14],
                blockR.0[16 * i + 15]
            );
        }

        // Apply Blake2 on rows of 64-bit words: (0, 1, 16, 17, ...112, 113), then
        // (2, 3, 18, 19, ..., 114, 115).. finally (14, 15, 30, 31, ..., 126, 127)
        for i in 0..8 {
            blake2_round!(
                blockR.0[2 * i],
                blockR.0[2 * i + 1],
                blockR.0[2 * i + 16],
                blockR.0[2 * i + 17],
                blockR.0[2 * i + 32],
                blockR.0[2 * i + 33],
                blockR.0[2 * i + 48],
                blockR.0[2 * i + 49],
                blockR.0[2 * i + 64],
                blockR.0[2 * i + 65],
                blockR.0[2 * i + 80],
                blockR.0[2 * i + 81],
                blockR.0[2 * i + 96],
                blockR.0[2 * i + 97],
                blockR.0[2 * i + 112],
                blockR.0[2 * i + 113]
            );
        }

        // TODO(tarcieri): get rid of this with `Copy`
        self.copy_block(&block_tmp);
        self.xor_block(&blockR);
    }
}

/// designed by the Lyra PHC team
fn fBlaMka(x: u64, y: u64) -> u64 {
    let m = 0xFFFFFFFF;
    let xy = Wrapping((x & m) * (y & m)) * Wrapping(2);
    (Wrapping(x) + Wrapping(y) + xy).0
}

fn rotr64(w: u64, c: u64) -> u64 {
    (w >> c) | (w << (64 - c))
}

/// BLAKE2b with an extended output
fn blake2b_long(inputs: &[&[u8]], mut out: &mut [u8]) -> Result<()> {
    if out.len() > u32::MAX as usize {
        return Err(Error::ARGON2_OUTPUT_TOO_LONG);
    }

    let outlen_bytes = (out.len() as u32).to_le_bytes();

    if out.len() <= BLAKE2B_OUTBYTES {
        let mut digest = VarBlake2b::new(out.len()).unwrap();
        digest::Update::update(&mut digest, &outlen_bytes);

        for input in inputs {
            digest::Update::update(&mut digest, input);
        }

        digest.finalize_variable(|hash| out.copy_from_slice(hash));
    } else {
        let mut digest = Blake2b::new();
        digest.update(&outlen_bytes);

        for input in inputs {
            digest.update(input);
        }

        let mut out_buffer = [0u8; BLAKE2B_OUTBYTES];
        out_buffer.copy_from_slice(&digest.finalize());

        out[..(BLAKE2B_OUTBYTES / 2)].copy_from_slice(&out_buffer[..(BLAKE2B_OUTBYTES / 2)]);
        out = &mut out[(BLAKE2B_OUTBYTES / 2)..];

        let mut in_buffer = [0u8; BLAKE2B_OUTBYTES];

        while out.len() > BLAKE2B_OUTBYTES {
            in_buffer.copy_from_slice(&out_buffer);
            out_buffer.copy_from_slice(&Blake2b::digest(&in_buffer));

            out[..(BLAKE2B_OUTBYTES / 2)].copy_from_slice(&out_buffer[..(BLAKE2B_OUTBYTES / 2)]);
            out = &mut out[(BLAKE2B_OUTBYTES / 2)..];
        }

        let mut digest = VarBlake2b::new(out.len()).unwrap();
        digest::Update::update(&mut digest, &out_buffer);
        digest.finalize_variable(|hash| out.copy_from_slice(hash));
    }

    Ok(())
}

/// Argon2 position: where we construct the block right now. Used to distribute
/// work between threads.
#[derive(Copy, Clone, Debug, Eq, PartialEq)]
pub struct Argon2_position {
    pass: u32,
    lane: u32,
    slice: u32,
    index: u32,
}
